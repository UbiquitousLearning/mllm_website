---
title: 快速开始
description: Get started with the mllm Lib.
sidebar:
  order: 2
---

import {LinkCard} from '@astrojs/starlight/components';
import Card from "/src/components/Card.astro"

**mllm** 是一个开源项目，您可以在您的项目中自由使用它。您可以在[GitHub](https://github.com/UbiquitousLearning/mllm)上找到源代码。
该项目也是公开开发和维护的，查看贡献指南看看您如何可以帮助。
<LinkCard
  title="贡献指南"
  description="了解如何为mllm做出贡献。"
  href="/contributing/contributing"
/>
## 在您开始之前

1. 克隆仓库
```bash
git clone https://github.com/UbiquitousLearning/mllm
```
2. 检查先决条件
虽然mllm是一个独立的库，但它需要一些工具来构建项目和一些其他库来加速推理。
 - gcc(11.4+) / clang (11.0+)
 - [CMake](https://cmake.org/) >= 3.18
 - OpenMP库
 - Android NDK工具链 >= 26

## 构建项目

:::note[构建目标]
目前，mllm可以在Android，Linux和macOS上运行，支持x86_64，arm64的架构。
:::

mllm提供两种形式的用户界面：<ins>命令行界面Demo</ins>和<ins>Android Demo应用</ins>。
<Card title="为CLI演示构建" icon="laptop">
CLI应用默认开启编译,您可以在bin或bin-arm目录中找到可执行文件。
:::tip
注意,在执行二进制文件之前,您需要将模型文件和Tokenizer 放置在当前目录下的models目录中。
:::
* 为本机操作系统HostOS构建：
```bash
cd scripts && ./build.sh
```
* 为Android构建：（需要NDK）
```bash
export ANDROID_NDK=/path/to/your/ndk
cd scripts && ./build_android.sh
```
二进制Demo应用应该位于bin或bin-arm目录中,如果需要在Android平台上测试命令行Demo,您可以使用`adb push`命令将二进制文件推送到设备上,并通过`adb shell`命令运行它。
:::tip
针对最常用的LLAMA模型,我们给出一个运行脚本来使用adb来快速测试mllm的性能。
在运行脚本前,您需要将模型文件和Tokenizer推送到设备 /data/local/tmp/mllm/models 目录下.
```bash
cd scripts && ./run_llama.sh
```
:::
</Card>
<Card title="为Android演示应用构建" icon="puzzle">
Android演示应用目前处于非常早期的阶段，并且它在一个单独的仓库中进行维护,并通过 `android` 这个子模块来引入.
:::tip
注意,当您使用Android Demo App时,您需要在启动App前将模型文件和Tokenizer vocab推送到设备 /sdcard/Download/model 目录下,并按照以下表格重命名.
:::

在您开始之前,建议先阅读`android` 子模块的`README.md`文件,以了解如何构建和运行Android Demo App,或者也可以访问[Chatbot Demo](https://github.com/lx200916/ChatBotApp/blob/master/README.md)来查阅最新版本的文档.
</Card>