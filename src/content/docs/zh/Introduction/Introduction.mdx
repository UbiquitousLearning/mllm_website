---
title: 介绍
description: 介绍mllm的特性和使用方法
prev: false
editLink: false
sidebar:
    order: 1
---

mllm是一款适用于移动和边缘设备的快速、轻量级的多模态LLM推理引擎。

* 纯C/C++实现，无依赖性
* 针对像fuyu-8B这样的多模态LLM进行了优化
* 支持：ARM NEON和x86 AVX2
* 4位和6位整数量化


## 试一试
mllm提供了一系列的[示例程序](https://github.com/UbiquitousLearning/mllm/examples)，包括使用mllm框架实现llama，clip，fuyu，vit，imagebind等。

此外，mllm还为安卓设备提供了[一个示例应用](https://github.com/UbiquitousLearning/mllm/android)，您可以通过adb将模型上传到您的手机，体验在mllm上不同模型推理的效果。

<style>
{`.demo-video td{
    width: 30%;
      text-align: center;
}`}
</style>
<table class="demo-video">
    <tr>
        <td>UI 屏幕阅读</td>
        <td>图像理解</td>
        <td>LLM 文字聊天</td>
    </tr>
    <tr>
        <td> <video loop controls="controls" muted auto-play src="/demo1.mp4"/> </td>
        <td> <video loop controls="controls" muted auto-play  src="/demo2.mp4"/> </td>
        <td>  <video loop controls="controls" muted auto-play  src="/demo3.mp4"/> </td>
    </tr>
</table>